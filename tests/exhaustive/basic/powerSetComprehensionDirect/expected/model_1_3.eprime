language ESSENCE' 1.0

given n: int
given a: int
given b: int
find x_Occurrence: matrix indexed by [int(a..b)] of bool
find x_ExplicitVarSizeWithMarker_Marker: int(0..1 + (b - a))
find x_ExplicitVarSizeWithMarker_Values: matrix indexed by [int(1..1 + (b - a))] of int(a..b)
branching on [x_ExplicitVarSizeWithMarker_Marker, x_ExplicitVarSizeWithMarker_Values, x_Occurrence]
such that
    and([and([x_Occurrence[t_ExplicitVarSizeWithDummy[q15]]
                  | q15 : int(1..1 + (b - a)), t_ExplicitVarSizeWithDummy[q15] != b + 1])
         ->
         sum([t_ExplicitVarSizeWithDummy[q16] | q16 : int(1..1 + (b - a)), t_ExplicitVarSizeWithDummy[q16] != b + 1]) <=
         6   | t_ExplicitVarSizeWithDummy : matrix indexed by [int(1..1 + (b - a))] of int(a..b + 1),
               and([t_ExplicitVarSizeWithDummy[q10] < t_ExplicitVarSizeWithDummy[q10 + 1] \/
                    t_ExplicitVarSizeWithDummy[q10] = b + 1
                        | q10 : int(1..1 + (b - a) - 1)]),
               and([t_ExplicitVarSizeWithDummy[q11] = b + 1 -> t_ExplicitVarSizeWithDummy[q11 + 1] = b + 1
                        | q11 : int(1..1 + (b - a) - 1)])]),
    n <= sum([toInt(x_Occurrence[q1]) | q1 : int(a..b)]),
    and([q2 + 1 <= x_ExplicitVarSizeWithMarker_Marker ->
         x_ExplicitVarSizeWithMarker_Values[q2] < x_ExplicitVarSizeWithMarker_Values[q2 + 1]
             | q2 : int(1..1 + (b - a) - 1)]),
    and([q3 > x_ExplicitVarSizeWithMarker_Marker -> x_ExplicitVarSizeWithMarker_Values[q3] = a
             | q3 : int(1..1 + (b - a))]),
    n <= x_ExplicitVarSizeWithMarker_Marker,
    and([q6 <= x_ExplicitVarSizeWithMarker_Marker -> x_Occurrence[x_ExplicitVarSizeWithMarker_Values[q6]]
             | q6 : int(1..1 + (b - a))]),
    and([x_Occurrence[q7] ->
         or([q9 <= x_ExplicitVarSizeWithMarker_Marker /\ x_ExplicitVarSizeWithMarker_Values[q9] = q7
                 | q9 : int(1..1 + (b - a))])
             | q7 : int(a..b)])

