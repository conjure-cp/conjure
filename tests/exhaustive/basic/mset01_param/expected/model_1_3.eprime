language ESSENCE' 1.0

given fin1: int
given g_ExplicitWithFlags_Flags: matrix indexed by [int(1..fin1)] of int(0..2)
given g_ExplicitWithFlags_Values: matrix indexed by [int(1..fin1)] of int(1..2)
find x_ExplicitWithFlags_Flags: matrix indexed by [int(1..4)] of int(0..2)
find x_ExplicitWithFlags_Values: matrix indexed by [int(1..4)] of int(1..2)
find x_MOccurrence: matrix indexed by [int(1..2)] of int(0..2)
branching on [x_MOccurrence, x_ExplicitWithFlags_Flags, x_ExplicitWithFlags_Values]
such that
    and([sum([g_ExplicitWithFlags_Flags[q15]
                  | q15 : int(1..fin1), g_ExplicitWithFlags_Values[q15] = g_ExplicitWithFlags_Values[q14]])
         =
         sum([toInt(x_ExplicitWithFlags_Values[q16] = g_ExplicitWithFlags_Values[q14]) *
              catchUndef(x_ExplicitWithFlags_Flags[q16], 0)
                  | q16 : int(1..4)])
             | q14 : int(1..fin1), g_ExplicitWithFlags_Flags[q14] > 0]),
    and([x_ExplicitWithFlags_Flags[q17] > 0 ->
         sum([toInt(g_ExplicitWithFlags_Values[q18] = x_ExplicitWithFlags_Values[q17]) *
              catchUndef(g_ExplicitWithFlags_Flags[q18], 0)
                  | q18 : int(1..fin1)])
         =
         sum([toInt(x_ExplicitWithFlags_Values[q19] = x_ExplicitWithFlags_Values[q17]) *
              catchUndef(x_ExplicitWithFlags_Flags[q19], 0)
                  | q19 : int(1..4)])
             | q17 : int(1..4)]),
    and([x_ExplicitWithFlags_Flags[q1 + 1] > 0 ->
         [x_ExplicitWithFlags_Values[q1]; int(1)] <lex [x_ExplicitWithFlags_Values[q1 + 1]; int(1)]
             | q1 : int(1..3)]),
    and([x_ExplicitWithFlags_Flags[q2] = 0 -> x_ExplicitWithFlags_Values[q2] = 1 | q2 : int(1..4)]),
    and([x_ExplicitWithFlags_Flags[q3 + 1] > 0 -> x_ExplicitWithFlags_Flags[q3] > 0 | q3 : int(1..3)]),
    sum([x_ExplicitWithFlags_Flags[q5] | q5 : int(1..4)]) <= 4,
    sum([x_MOccurrence[q7] | q7 : int(1..2)]) <= 4,
    and([x_MOccurrence[q9] > 0 ->
         x_MOccurrence[q9] =
         sum([toInt(x_ExplicitWithFlags_Values[q10] = q9) * catchUndef(x_ExplicitWithFlags_Flags[q10], 0)
                  | q10 : int(1..4)])
             | q9 : int(1..2)]),
    and([x_ExplicitWithFlags_Flags[q11] > 0 ->
         x_MOccurrence[x_ExplicitWithFlags_Values[q11]] =
         sum([toInt(x_ExplicitWithFlags_Values[q12] = x_ExplicitWithFlags_Values[q11]) *
              catchUndef(x_ExplicitWithFlags_Flags[q12], 0)
                  | q12 : int(1..4)])
             | q11 : int(1..4)])

