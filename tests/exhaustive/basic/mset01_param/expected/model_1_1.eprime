language ESSENCE' 1.0

given fin1: int
given g_ExplicitWithFlags_Flags: matrix indexed by [int(1..fin1)] of int(0..2)
given g_ExplicitWithFlags_Values: matrix indexed by [int(1..fin1)] of int(1..2)
find x_ExplicitWithFlags_Flags: matrix indexed by [int(1..4)] of int(0..2)
find x_ExplicitWithFlags_Values: matrix indexed by [int(1..4)] of int(1..2)
branching on [x_ExplicitWithFlags_Flags, x_ExplicitWithFlags_Values]
such that
    and([sum([g_ExplicitWithFlags_Flags[q9]
                  | q9 : int(1..fin1), g_ExplicitWithFlags_Values[q9] = g_ExplicitWithFlags_Values[q8]])
         =
         sum([toInt(x_ExplicitWithFlags_Values[q10] = g_ExplicitWithFlags_Values[q8]) *
              catchUndef(x_ExplicitWithFlags_Flags[q10], 0)
                  | q10 : int(1..4)])
             | q8 : int(1..fin1), g_ExplicitWithFlags_Flags[q8] > 0]),
    and([x_ExplicitWithFlags_Flags[q11] > 0 ->
         sum([toInt(g_ExplicitWithFlags_Values[q12] = x_ExplicitWithFlags_Values[q11]) *
              catchUndef(g_ExplicitWithFlags_Flags[q12], 0)
                  | q12 : int(1..fin1)])
         =
         sum([toInt(x_ExplicitWithFlags_Values[q13] = x_ExplicitWithFlags_Values[q11]) *
              catchUndef(x_ExplicitWithFlags_Flags[q13], 0)
                  | q13 : int(1..4)])
             | q11 : int(1..4)]),
    and([x_ExplicitWithFlags_Flags[q1 + 1] > 0 ->
         [x_ExplicitWithFlags_Values[q1]; int(1)] <lex [x_ExplicitWithFlags_Values[q1 + 1]; int(1)]
             | q1 : int(1..3)]),
    and([x_ExplicitWithFlags_Flags[q2] = 0 -> x_ExplicitWithFlags_Values[q2] = 1 | q2 : int(1..4)]),
    and([x_ExplicitWithFlags_Flags[q3 + 1] > 0 -> x_ExplicitWithFlags_Flags[q3] > 0 | q3 : int(1..3)]),
    sum([x_ExplicitWithFlags_Flags[q5] | q5 : int(1..4)]) <= 4

