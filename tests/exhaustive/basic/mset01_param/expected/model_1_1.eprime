language ESSENCE' 1.0

given fin1: int
given g_ExplicitWithFlags_Flags: matrix indexed by [int(1..fin1)] of int(0..2)
given g_ExplicitWithFlags_Values: matrix indexed by [int(1..fin1)] of int(1..2)
find x_ExplicitWithFlags_Flags: matrix indexed by [int(1..4)] of int(0..2)
find x_ExplicitWithFlags_Values: matrix indexed by [int(1..4)] of int(1..2)
branching on [x_ExplicitWithFlags_Flags, x_ExplicitWithFlags_Values]
such that
    and([sum([g_ExplicitWithFlags_Flags[q10]
                  | q10 : int(1..fin1), g_ExplicitWithFlags_Values[q10] = g_ExplicitWithFlags_Values[q9]])
         =
         sum([toInt(x_ExplicitWithFlags_Values[q11] = g_ExplicitWithFlags_Values[q9]) *
              catchUndef(x_ExplicitWithFlags_Flags[q11], 0)
                  | q11 : int(1..4)])
             | q9 : int(1..fin1), g_ExplicitWithFlags_Flags[q9] > 0]),
    and([x_ExplicitWithFlags_Flags[q12] > 0 ->
         sum([toInt(g_ExplicitWithFlags_Values[q13] = x_ExplicitWithFlags_Values[q12]) *
              catchUndef(g_ExplicitWithFlags_Flags[q13], 0)
                  | q13 : int(1..fin1)])
         =
         sum([toInt(x_ExplicitWithFlags_Values[q14] = x_ExplicitWithFlags_Values[q12]) *
              catchUndef(x_ExplicitWithFlags_Flags[q14], 0)
                  | q14 : int(1..4)])
             | q12 : int(1..4)]),
    and([x_ExplicitWithFlags_Flags[q1 + 1] > 0 -> x_ExplicitWithFlags_Values[q1] < x_ExplicitWithFlags_Values[q1 + 1]
             | q1 : int(1..3)]),
    and([x_ExplicitWithFlags_Flags[q2] = 0 -> x_ExplicitWithFlags_Values[q2] = 1 | q2 : int(1..4)]),
    and([x_ExplicitWithFlags_Flags[q3 + 1] > 0 -> x_ExplicitWithFlags_Flags[q3] > 0 | q3 : int(1..3)]),
    sum([x_ExplicitWithFlags_Flags[q6] | q6 : int(1..4)]) <= 4

